{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acb88175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data context:\n",
    "\"\"\"\n",
    "https://www.kaggle.com/datasets/brunogrisci/breast-cancer-gene-expression-cumida\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os \n",
    "\n",
    "os.getcwd()\n",
    "dir_ = 'C://Users//Domin/Downloads'\n",
    "os.chdir(dir_)\n",
    "\n",
    "os.getcwd()\n",
    "import pandas as pd\n",
    "import numpy \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99e1af5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>1007_s_at</th>\n",
       "      <th>1053_at</th>\n",
       "      <th>117_at</th>\n",
       "      <th>121_at</th>\n",
       "      <th>1255_g_at</th>\n",
       "      <th>1294_at</th>\n",
       "      <th>1316_at</th>\n",
       "      <th>1320_at</th>\n",
       "      <th>1405_i_at</th>\n",
       "      <th>...</th>\n",
       "      <th>206926_s_at</th>\n",
       "      <th>206927_s_at</th>\n",
       "      <th>206928_at</th>\n",
       "      <th>206929_s_at</th>\n",
       "      <th>206930_at</th>\n",
       "      <th>206931_at</th>\n",
       "      <th>206932_at</th>\n",
       "      <th>206933_s_at</th>\n",
       "      <th>206934_at</th>\n",
       "      <th>206935_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>basal</td>\n",
       "      <td>9.850040</td>\n",
       "      <td>8.097927</td>\n",
       "      <td>6.424728</td>\n",
       "      <td>7.353027</td>\n",
       "      <td>3.029122</td>\n",
       "      <td>6.880079</td>\n",
       "      <td>4.963740</td>\n",
       "      <td>4.408328</td>\n",
       "      <td>8.870780</td>\n",
       "      <td>...</td>\n",
       "      <td>6.167506</td>\n",
       "      <td>4.157291</td>\n",
       "      <td>8.463251</td>\n",
       "      <td>8.233774</td>\n",
       "      <td>3.440250</td>\n",
       "      <td>3.249266</td>\n",
       "      <td>4.077760</td>\n",
       "      <td>5.114589</td>\n",
       "      <td>3.649391</td>\n",
       "      <td>3.048597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>basal</td>\n",
       "      <td>9.861357</td>\n",
       "      <td>8.212222</td>\n",
       "      <td>7.062593</td>\n",
       "      <td>7.685578</td>\n",
       "      <td>3.149468</td>\n",
       "      <td>7.542283</td>\n",
       "      <td>5.129607</td>\n",
       "      <td>4.584418</td>\n",
       "      <td>7.767646</td>\n",
       "      <td>...</td>\n",
       "      <td>6.016303</td>\n",
       "      <td>3.746938</td>\n",
       "      <td>9.166471</td>\n",
       "      <td>7.922956</td>\n",
       "      <td>2.832078</td>\n",
       "      <td>3.563185</td>\n",
       "      <td>4.457529</td>\n",
       "      <td>4.774928</td>\n",
       "      <td>3.886136</td>\n",
       "      <td>4.945811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>basal</td>\n",
       "      <td>10.103478</td>\n",
       "      <td>8.936137</td>\n",
       "      <td>5.735970</td>\n",
       "      <td>7.687822</td>\n",
       "      <td>3.125931</td>\n",
       "      <td>6.562369</td>\n",
       "      <td>4.813449</td>\n",
       "      <td>4.425195</td>\n",
       "      <td>9.417956</td>\n",
       "      <td>...</td>\n",
       "      <td>6.298974</td>\n",
       "      <td>3.818161</td>\n",
       "      <td>8.691060</td>\n",
       "      <td>7.209782</td>\n",
       "      <td>3.371737</td>\n",
       "      <td>3.500604</td>\n",
       "      <td>4.909135</td>\n",
       "      <td>4.619495</td>\n",
       "      <td>3.393670</td>\n",
       "      <td>2.940155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basal</td>\n",
       "      <td>9.756875</td>\n",
       "      <td>7.357148</td>\n",
       "      <td>6.479183</td>\n",
       "      <td>6.986624</td>\n",
       "      <td>3.181638</td>\n",
       "      <td>7.802344</td>\n",
       "      <td>5.490982</td>\n",
       "      <td>4.567956</td>\n",
       "      <td>9.022345</td>\n",
       "      <td>...</td>\n",
       "      <td>5.924285</td>\n",
       "      <td>3.799996</td>\n",
       "      <td>8.519125</td>\n",
       "      <td>7.011523</td>\n",
       "      <td>3.412964</td>\n",
       "      <td>3.716722</td>\n",
       "      <td>4.822208</td>\n",
       "      <td>4.792745</td>\n",
       "      <td>3.619956</td>\n",
       "      <td>2.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>basal</td>\n",
       "      <td>9.408330</td>\n",
       "      <td>7.746404</td>\n",
       "      <td>6.693980</td>\n",
       "      <td>7.333426</td>\n",
       "      <td>3.169923</td>\n",
       "      <td>7.610457</td>\n",
       "      <td>5.372469</td>\n",
       "      <td>4.424426</td>\n",
       "      <td>9.400056</td>\n",
       "      <td>...</td>\n",
       "      <td>5.984826</td>\n",
       "      <td>4.005609</td>\n",
       "      <td>9.199242</td>\n",
       "      <td>7.460834</td>\n",
       "      <td>3.155281</td>\n",
       "      <td>4.028018</td>\n",
       "      <td>5.705145</td>\n",
       "      <td>4.477804</td>\n",
       "      <td>3.724393</td>\n",
       "      <td>2.829142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16383 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    type  1007_s_at   1053_at    117_at    121_at  1255_g_at   1294_at  \\\n",
       "0  basal   9.850040  8.097927  6.424728  7.353027   3.029122  6.880079   \n",
       "1  basal   9.861357  8.212222  7.062593  7.685578   3.149468  7.542283   \n",
       "2  basal  10.103478  8.936137  5.735970  7.687822   3.125931  6.562369   \n",
       "3  basal   9.756875  7.357148  6.479183  6.986624   3.181638  7.802344   \n",
       "4  basal   9.408330  7.746404  6.693980  7.333426   3.169923  7.610457   \n",
       "\n",
       "    1316_at   1320_at  1405_i_at  ...  206926_s_at  206927_s_at  206928_at  \\\n",
       "0  4.963740  4.408328   8.870780  ...     6.167506     4.157291   8.463251   \n",
       "1  5.129607  4.584418   7.767646  ...     6.016303     3.746938   9.166471   \n",
       "2  4.813449  4.425195   9.417956  ...     6.298974     3.818161   8.691060   \n",
       "3  5.490982  4.567956   9.022345  ...     5.924285     3.799996   8.519125   \n",
       "4  5.372469  4.424426   9.400056  ...     5.984826     4.005609   9.199242   \n",
       "\n",
       "   206929_s_at  206930_at  206931_at  206932_at  206933_s_at  206934_at  \\\n",
       "0     8.233774   3.440250   3.249266   4.077760     5.114589   3.649391   \n",
       "1     7.922956   2.832078   3.563185   4.457529     4.774928   3.886136   \n",
       "2     7.209782   3.371737   3.500604   4.909135     4.619495   3.393670   \n",
       "3     7.011523   3.412964   3.716722   4.822208     4.792745   3.619956   \n",
       "4     7.460834   3.155281   4.028018   5.705145     4.477804   3.724393   \n",
       "\n",
       "   206935_at  \n",
       "0   3.048597  \n",
       "1   4.945811  \n",
       "2   2.940155  \n",
       "3   2.710000  \n",
       "4   2.829142  \n",
       "\n",
       "[5 rows x 16383 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('breast_cancer_bioinformatics.csv')\n",
    "\n",
    "#lets do a little exploratory analysis \n",
    "\n",
    "data.dropna(axis = 1)\n",
    "data.head()\n",
    "\n",
    "#Over 16,000 genes !!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b2ddc75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "basal        41\n",
       "HER          30\n",
       "luminal_B    30\n",
       "luminal_A    29\n",
       "cell_line    14\n",
       "normal        7\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "labeler = LabelEncoder()\n",
    "y = data['type'] \n",
    "x = data.drop(['type'], axis = 1) \n",
    "x_copy = x \n",
    "y_copy = y\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "y.value_counts()\n",
    "\n",
    "#six dimensions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7bb070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c47470e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb219b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 24)\n",
    "\n",
    "y_train = labeler.fit_transform(y_train)\n",
    "y_test = labeler.fit_transform(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42b6c2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "X_train_copy = X_train\n",
    "y_train_copy = y_train\n",
    "\n",
    "\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9b8b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2585a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified version - borrowed some code and modified for the functions\n",
    "\n",
    "\n",
    "class NeuralNetworkClassificationModel(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super(NeuralNetworkClassificationModel,self).__init__()\n",
    "        self.input_layer    = nn.Linear(input_dim,300)\n",
    "        self.hidden_layer1  = nn.Linear(300,64)\n",
    "        self.output_layer   = nn.Linear(64,output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    \n",
    "    def forward(self,x):\n",
    "        out =  self.relu(self.input_layer(x))\n",
    "        out =  self.relu(self.hidden_layer1(out))\n",
    "        out =  self.output_layer(out)\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6c3b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_dim  = 16382\n",
    "output_dim = 6\n",
    "model = NeuralNetworkClassificationModel(input_dim,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75a0c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our optimizer and loss function object\n",
    "learning_rate = 0.0001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec583d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "351c4ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model,optimizer,criterion,X_train,y_train,X_test,y_test,num_epochs,train_losses,test_losses):\n",
    "    for epoch in range(num_epochs):\n",
    "        #clear out the gradients from the last step loss.backward()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward feed\n",
    "        output_train = model(X_train)\n",
    "\n",
    "        #calculate the loss\n",
    "        loss_train = criterion(output_train, y_train)\n",
    "        \n",
    "\n",
    "\n",
    "        #backward propagation: calculate gradients\n",
    "        loss_train.backward()\n",
    "\n",
    "        #update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        output_test = model(X_test)\n",
    "        loss_test = criterion(output_test,y_test)\n",
    "\n",
    "        train_losses[epoch] = loss_train.item()\n",
    "        test_losses[epoch] = loss_test.item()\n",
    "\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {loss_train.item():.4f}, Test Loss: {loss_test.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa45b27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "train_losses = np.zeros(num_epochs)\n",
    "test_losses  = np.zeros(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e184b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000, Train Loss: 0.0019, Test Loss: 0.2339\n",
      "Epoch 100/1000, Train Loss: 0.0009, Test Loss: 0.2221\n",
      "Epoch 150/1000, Train Loss: 0.0006, Test Loss: 0.2180\n",
      "Epoch 200/1000, Train Loss: 0.0004, Test Loss: 0.2156\n",
      "Epoch 250/1000, Train Loss: 0.0003, Test Loss: 0.2136\n",
      "Epoch 300/1000, Train Loss: 0.0003, Test Loss: 0.2120\n",
      "Epoch 350/1000, Train Loss: 0.0002, Test Loss: 0.2107\n",
      "Epoch 400/1000, Train Loss: 0.0002, Test Loss: 0.2099\n",
      "Epoch 450/1000, Train Loss: 0.0001, Test Loss: 0.2091\n",
      "Epoch 500/1000, Train Loss: 0.0001, Test Loss: 0.2086\n",
      "Epoch 550/1000, Train Loss: 0.0001, Test Loss: 0.2083\n",
      "Epoch 600/1000, Train Loss: 0.0001, Test Loss: 0.2081\n",
      "Epoch 650/1000, Train Loss: 0.0001, Test Loss: 0.2078\n",
      "Epoch 700/1000, Train Loss: 0.0001, Test Loss: 0.2076\n",
      "Epoch 750/1000, Train Loss: 0.0001, Test Loss: 0.2074\n",
      "Epoch 800/1000, Train Loss: 0.0001, Test Loss: 0.2071\n",
      "Epoch 850/1000, Train Loss: 0.0000, Test Loss: 0.2068\n",
      "Epoch 900/1000, Train Loss: 0.0000, Test Loss: 0.2065\n",
      "Epoch 950/1000, Train Loss: 0.0000, Test Loss: 0.2063\n",
      "Epoch 1000/1000, Train Loss: 0.0000, Test Loss: 0.2062\n"
     ]
    }
   ],
   "source": [
    "train_network(model,optimizer,criterion,X_train,y_train,X_test,y_test,num_epochs,train_losses,test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f05a65fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = []\n",
    "predictions_test =  []\n",
    "with torch.no_grad():\n",
    "    predictions_train = model(X_train)\n",
    "    predictions_test = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e273458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_multiclass(pred_arr,original_arr):\n",
    "    if len(pred_arr)!=len(original_arr):\n",
    "        return False\n",
    "    pred_arr = pred_arr.numpy()\n",
    "    original_arr = original_arr.numpy()\n",
    "    final_pred= []\n",
    "  \n",
    "    for i in range(len(pred_arr)):\n",
    "        final_pred.append(np.argmax(pred_arr[i]))\n",
    "    final_pred = np.array(final_pred)\n",
    "    count = 0\n",
    "    #here we are doing a simple comparison between the predicted_arr and the original_arr to get the final accuracy\n",
    "    for i in range(len(original_arr)):\n",
    "        if final_pred[i] == original_arr[i]:\n",
    "            count+=1\n",
    "    return count/len(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "474cc557",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = get_accuracy_multiclass(predictions_train,y_train)\n",
    "test_acc  = get_accuracy_multiclass(predictions_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "feaf5c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 100.0\n",
      "Test Accuracy: 93.548\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Accuracy: {round(train_acc*100,3)}\")\n",
    "print(f\"Test Accuracy: {round(test_acc*100,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc67bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nice, we got 93% accuracy! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff08a72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets see what we would have gotten with a Logistic Regression algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07e20036",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.numpy()\n",
    "X_test = X_test.numpy()\n",
    "y_train = y_train.numpy()\n",
    "y_test = y_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc00f66a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ddefc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "915eb531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Domin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cde6e95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Score:  0.9354838709677419 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = log_model.predict(X_test)\n",
    "\n",
    "print('\\nModel Score: ',log_model.score(X_test, y_test),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffe8f7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interesting - it got a very similar score! \n",
    "\n",
    "\n",
    "# get importance - if possible\n",
    "importance = log_model.coef_[0]\n",
    "gene_names = x.columns\n",
    "gene_list, importance_list = [], []\n",
    "    \n",
    "for i,v in enumerate(importance):\n",
    "    gene_list.append(x.columns[i])\n",
    "    importance_list.append(importance[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f9714e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff53dab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca52e974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genes</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1007_s_at</td>\n",
       "      <td>0.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1053_at</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>117_at</td>\n",
       "      <td>-0.003272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121_at</td>\n",
       "      <td>0.001003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1255_g_at</td>\n",
       "      <td>0.001907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Genes  Importance\n",
       "0  1007_s_at    0.001400\n",
       "1    1053_at    0.000018\n",
       "2     117_at   -0.003272\n",
       "3     121_at    0.001003\n",
       "4  1255_g_at    0.001907"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Genes'] = gene_list\n",
    "df['Importance'] = importance\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8386074a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['202991_at',\n",
       " '201207_at',\n",
       " '1559697_a_at',\n",
       " '1566968_at',\n",
       " '1565635_at',\n",
       " '204323_x_at',\n",
       " '206793_at',\n",
       " '204909_at',\n",
       " '1560556_a_at',\n",
       " '204325_s_at']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets get the ten most 'important' genes \n",
    "df = df.sort_values(by = 'Importance', ascending = False)\n",
    "df_copy = df\n",
    "#now let's snip these genes \n",
    "\n",
    "df = df.iloc[0:10]\n",
    "gene_list = df['Genes'].tolist()\n",
    "\n",
    "gene_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22f8309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_copy_updated = x_copy[['202991_at',\n",
    " '201207_at',\n",
    " '1559697_a_at',\n",
    " '1566968_at',\n",
    " '1565635_at',\n",
    " '204323_x_at',\n",
    " '206793_at',\n",
    " '204909_at',\n",
    " '1560556_a_at',\n",
    " '204325_s_at']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "502f8d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_copy_updated, y, test_size = 0.20, random_state = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37760d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Domin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "231fcdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Score:  0.7096774193548387 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = log_model.predict(X_test)\n",
    "\n",
    "print('\\nModel Score: ',log_model.score(X_test, y_test),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55e62fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genes</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12440</th>\n",
       "      <td>202991_at</td>\n",
       "      <td>0.009588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10655</th>\n",
       "      <td>201207_at</td>\n",
       "      <td>0.008557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4951</th>\n",
       "      <td>1559697_a_at</td>\n",
       "      <td>0.008429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8537</th>\n",
       "      <td>1566968_at</td>\n",
       "      <td>0.008417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7911</th>\n",
       "      <td>1565635_at</td>\n",
       "      <td>0.008409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Genes  Importance\n",
       "12440     202991_at    0.009588\n",
       "10655     201207_at    0.008557\n",
       "4951   1559697_a_at    0.008429\n",
       "8537     1566968_at    0.008417\n",
       "7911     1565635_at    0.008409"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Not super great - but definitely not terrible. 70% accuracy with only ten of the thousands of other genes!\n",
    "#Seems we may be getting diminising returns? \n",
    "#Let's see what would happen if we chose the top 25 instead \n",
    "\n",
    "\n",
    "top_25_genes = df_copy.iloc[0:25]\n",
    "top_25_genes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbf9fa6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>202991_at</th>\n",
       "      <th>201207_at</th>\n",
       "      <th>1559697_a_at</th>\n",
       "      <th>1566968_at</th>\n",
       "      <th>1565635_at</th>\n",
       "      <th>204323_x_at</th>\n",
       "      <th>206793_at</th>\n",
       "      <th>204909_at</th>\n",
       "      <th>1560556_a_at</th>\n",
       "      <th>204325_s_at</th>\n",
       "      <th>...</th>\n",
       "      <th>204915_s_at</th>\n",
       "      <th>205365_at</th>\n",
       "      <th>206165_s_at</th>\n",
       "      <th>1552801_at</th>\n",
       "      <th>1559696_at</th>\n",
       "      <th>206166_s_at</th>\n",
       "      <th>206199_at</th>\n",
       "      <th>1556923_at</th>\n",
       "      <th>201208_s_at</th>\n",
       "      <th>201388_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.989758</td>\n",
       "      <td>7.870343</td>\n",
       "      <td>3.732465</td>\n",
       "      <td>6.518358</td>\n",
       "      <td>4.014064</td>\n",
       "      <td>6.250654</td>\n",
       "      <td>5.486211</td>\n",
       "      <td>4.852879</td>\n",
       "      <td>3.327970</td>\n",
       "      <td>4.808402</td>\n",
       "      <td>...</td>\n",
       "      <td>6.959162</td>\n",
       "      <td>3.831934</td>\n",
       "      <td>3.099799</td>\n",
       "      <td>3.573151</td>\n",
       "      <td>4.169292</td>\n",
       "      <td>3.382761</td>\n",
       "      <td>3.408623</td>\n",
       "      <td>6.260609</td>\n",
       "      <td>7.047056</td>\n",
       "      <td>8.484028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.138559</td>\n",
       "      <td>7.757607</td>\n",
       "      <td>3.522690</td>\n",
       "      <td>6.697095</td>\n",
       "      <td>4.816689</td>\n",
       "      <td>6.349760</td>\n",
       "      <td>5.315597</td>\n",
       "      <td>4.510545</td>\n",
       "      <td>4.133971</td>\n",
       "      <td>4.049191</td>\n",
       "      <td>...</td>\n",
       "      <td>6.502029</td>\n",
       "      <td>3.350953</td>\n",
       "      <td>3.383245</td>\n",
       "      <td>3.668351</td>\n",
       "      <td>3.947331</td>\n",
       "      <td>3.198395</td>\n",
       "      <td>3.386591</td>\n",
       "      <td>5.191695</td>\n",
       "      <td>6.712379</td>\n",
       "      <td>8.095460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.014003</td>\n",
       "      <td>7.331337</td>\n",
       "      <td>3.358369</td>\n",
       "      <td>5.381590</td>\n",
       "      <td>3.731272</td>\n",
       "      <td>6.584204</td>\n",
       "      <td>5.110619</td>\n",
       "      <td>4.627865</td>\n",
       "      <td>3.298836</td>\n",
       "      <td>5.708482</td>\n",
       "      <td>...</td>\n",
       "      <td>3.918706</td>\n",
       "      <td>3.370024</td>\n",
       "      <td>3.222324</td>\n",
       "      <td>4.382866</td>\n",
       "      <td>3.951010</td>\n",
       "      <td>3.547763</td>\n",
       "      <td>3.329935</td>\n",
       "      <td>4.152518</td>\n",
       "      <td>6.372206</td>\n",
       "      <td>8.249896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.546919</td>\n",
       "      <td>7.664019</td>\n",
       "      <td>3.362631</td>\n",
       "      <td>6.177053</td>\n",
       "      <td>3.488158</td>\n",
       "      <td>5.997989</td>\n",
       "      <td>5.496236</td>\n",
       "      <td>4.502260</td>\n",
       "      <td>3.294319</td>\n",
       "      <td>4.257647</td>\n",
       "      <td>...</td>\n",
       "      <td>6.249711</td>\n",
       "      <td>3.461685</td>\n",
       "      <td>3.781336</td>\n",
       "      <td>3.679822</td>\n",
       "      <td>3.730990</td>\n",
       "      <td>3.632173</td>\n",
       "      <td>3.020432</td>\n",
       "      <td>5.986792</td>\n",
       "      <td>6.681212</td>\n",
       "      <td>9.538022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.596304</td>\n",
       "      <td>8.104621</td>\n",
       "      <td>3.477564</td>\n",
       "      <td>6.382301</td>\n",
       "      <td>4.033350</td>\n",
       "      <td>6.752754</td>\n",
       "      <td>5.494223</td>\n",
       "      <td>4.662594</td>\n",
       "      <td>3.922545</td>\n",
       "      <td>4.859110</td>\n",
       "      <td>...</td>\n",
       "      <td>6.054351</td>\n",
       "      <td>3.522720</td>\n",
       "      <td>3.039264</td>\n",
       "      <td>3.605025</td>\n",
       "      <td>3.658386</td>\n",
       "      <td>3.311291</td>\n",
       "      <td>3.270831</td>\n",
       "      <td>5.424712</td>\n",
       "      <td>7.008956</td>\n",
       "      <td>9.764372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   202991_at  201207_at  1559697_a_at  1566968_at  1565635_at  204323_x_at  \\\n",
       "0   5.989758   7.870343      3.732465    6.518358    4.014064     6.250654   \n",
       "1   6.138559   7.757607      3.522690    6.697095    4.816689     6.349760   \n",
       "2   6.014003   7.331337      3.358369    5.381590    3.731272     6.584204   \n",
       "3   6.546919   7.664019      3.362631    6.177053    3.488158     5.997989   \n",
       "4   6.596304   8.104621      3.477564    6.382301    4.033350     6.752754   \n",
       "\n",
       "   206793_at  204909_at  1560556_a_at  204325_s_at  ...  204915_s_at  \\\n",
       "0   5.486211   4.852879      3.327970     4.808402  ...     6.959162   \n",
       "1   5.315597   4.510545      4.133971     4.049191  ...     6.502029   \n",
       "2   5.110619   4.627865      3.298836     5.708482  ...     3.918706   \n",
       "3   5.496236   4.502260      3.294319     4.257647  ...     6.249711   \n",
       "4   5.494223   4.662594      3.922545     4.859110  ...     6.054351   \n",
       "\n",
       "   205365_at  206165_s_at  1552801_at  1559696_at  206166_s_at  206199_at  \\\n",
       "0   3.831934     3.099799    3.573151    4.169292     3.382761   3.408623   \n",
       "1   3.350953     3.383245    3.668351    3.947331     3.198395   3.386591   \n",
       "2   3.370024     3.222324    4.382866    3.951010     3.547763   3.329935   \n",
       "3   3.461685     3.781336    3.679822    3.730990     3.632173   3.020432   \n",
       "4   3.522720     3.039264    3.605025    3.658386     3.311291   3.270831   \n",
       "\n",
       "   1556923_at  201208_s_at  201388_at  \n",
       "0    6.260609     7.047056   8.484028  \n",
       "1    5.191695     6.712379   8.095460  \n",
       "2    4.152518     6.372206   8.249896  \n",
       "3    5.986792     6.681212   9.538022  \n",
       "4    5.424712     7.008956   9.764372  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_25_list = top_25_genes['Genes'].tolist()\n",
    "updated_df = x_copy\n",
    "\n",
    "updated_df_25 = updated_df[top_25_list]\n",
    "updated_df_25.head()\n",
    "\n",
    "#excellent! now lets see by how much this improves the score (if any) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a73847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(updated_df_25, y, test_size = 0.20, random_state = 24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11798c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Domin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31e797f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Score:  0.9032258064516129 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = log_model.predict(X_test)\n",
    "\n",
    "print('\\nModel Score: ',log_model.score(X_test, y_test),'\\n')\n",
    "\n",
    "# wow, it turns out that only 25 of these genes are sufficient in achieving 90% accuracy! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2746be9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 0 0 0 0 0]\n",
      " [0 8 0 0 0 0]\n",
      " [0 1 0 0 0 1]\n",
      " [0 0 0 9 0 1]\n",
      " [0 0 0 0 6 0]\n",
      " [0 0 0 0 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         HER       1.00      1.00      1.00         5\n",
      "       basal       0.89      1.00      0.94         8\n",
      "   cell_line       0.00      0.00      0.00         2\n",
      "   luminal_A       1.00      0.90      0.95        10\n",
      "   luminal_B       1.00      1.00      1.00         6\n",
      "      normal       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90        31\n",
      "   macro avg       0.65      0.65      0.65        31\n",
      "weighted avg       0.91      0.90      0.90        31\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Domin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Domin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Domin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Domin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Domin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Domin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#man it looks like we are really missing out on cell line and normal - maybe \n",
    "#our algorithm needs some tuning/updating? \n",
    "\n",
    "#will return with an updated version to handle the class imbalances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ccbcc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 698.3870000000001,
   "position": {
    "height": "720.769px",
    "left": "1447.87px",
    "right": "20px",
    "top": "49.9px",
    "width": "743.344px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
